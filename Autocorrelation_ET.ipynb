{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autocorrelation of Eye Tracking Data\n",
    "This notebook calculates the autocorrelation of raw eye tracking data. \n",
    "\n",
    "Objectives:\n",
    "* Autocorrelation plot showing time points with especially high correlation within the time series of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General configuration\n",
    "import os\n",
    "\n",
    "# data_directory: str\n",
    "#     Path to a directory to store data.\n",
    "data_directory = '.'\n",
    "\n",
    "# install_missing_packages: bool\n",
    "#     A flag indicating if missing packages should be automatically installed\n",
    "install_missing_packages = True\n",
    "\n",
    "# use_conda: bool\n",
    "#     A flag indicating if conda should be used for software installation.\n",
    "#     If False, pip will be used. The default is to use conda if jupyter\n",
    "#     is run in a conda environment.\n",
    "use_conda = 'CONDA_EXE' in os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for missing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "def check_package(package, pip_pkg: str = None, conda_pkg: str = None):\n",
    "    \"\"\"Check if a given package is installed. If missing install\n",
    "    it (if global flag `install_missing_packages` is True) either with\n",
    "    pip or with conda (depending on `use_conda`).\n",
    "    \"\"\"\n",
    "    if importlib.util.find_spec(package) is not None:\n",
    "        return  # ok, package is already installed\n",
    "\n",
    "    if not install_missing_packages:\n",
    "        raise RuntimeError(f\"{package} is not installed!\")\n",
    "\n",
    "    if use_conda:\n",
    "        import conda.cli\n",
    "        conda.cli.main('conda', 'install',  '-y', conda_pkg or package)\n",
    "    else:\n",
    "        import subprocess\n",
    "        import sys            \n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pip_pkg or package])\n",
    "        \n",
    "# This is to exit cells without error tracebacks (cosmetic purpose)\n",
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "To run all of this notebook, you need the following libraries to be installed:\n",
    "* ImageIO (`imageio` and `imageio-ffmpeg`): for reading images and accessing the webcam\n",
    "* Scikit-image (`scikit-image`) for some image manipulation\n",
    "* MatPlotLib (`matplotlib`): mainly for displaying images in the notebook\n",
    "* Dlib (`dlib`) providing the HOG face detector\n",
    "* OpenCV (`opencv`) for real time applications\n",
    "* Imutils (`imutils`) for image manipulation with OpenCV\n",
    "\n",
    "Running the following cell will create a file `graphs.yml` that can be used to setup a conda environment containing the required packages. If you already downloaded the file from my GitHub, skip the next cell and create the env directly from it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile graphs.yml\n",
    "name: graphs\n",
    "channels:\n",
    "  - conda-forge\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python=3.6\n",
    "  - jupyter\n",
    "  - imageio\n",
    "  - imageio-ffmpeg\n",
    "  - matplotlib\n",
    "  - scikit-image\n",
    "  - opencv\n",
    "  - networkx\n",
    "  - pandas\n",
    "  - statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Creation\n",
    "\n",
    "To create the environment, open the. terminal, go to the directory where you stored the graphs.yml file (the directory of the notebook) and type\n",
    "```sh\n",
    "conda env create -f graphs.yml\n",
    "```\n",
    "After running this command you have to activate the environment (Linux/MacOS: `conda activate graphs`, Windows: `activate graphs`) and then reopen the notebook in that environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main part\n",
    "### Imports and directory definition\n",
    "The data directory is adjusted to the folder arrangedment of the github repo. Adjust if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as nX\n",
    "import glob\n",
    "from sklearn.preprocessing import normalize\n",
    "from pandas.plotting import autocorrelation_plot as AC_plot \n",
    "from statsmodels.graphics import tsaplots\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from skimage.filters import gaussian\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.signal import argrelextrema\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "\n",
    "OG_DATA_PATH = './'\n",
    "DATA_PATH = './EyesOnScreen/'\n",
    "PROCESSED_DATA_PATH = './Results/Autocorrelation/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation Part\n",
    "\n",
    "### Loading\n",
    "* Loading in the EyesOnScreen data (the ET based hit coordinates on the HMD screen) consisting of X and Y coordinates.\n",
    "\n",
    "### Calculation\n",
    "* Using the statsmodels acf autocorrelation function to calculate the autocorrelation for every time shift of the coordinate series (for each coordinate separately).\n",
    "* I save these into a table.\n",
    "* Afterwards, using the 10 second mark, calculating a measure of variance for all following extrema\n",
    "\n",
    "### Plotting\n",
    "* Plotting the autocorrelation plot of each coordinate separately\n",
    "\n",
    "### Saving\n",
    "* Saving the plot and autocorrelation table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation \n",
    "# If you want to plot\n",
    "plotting_wanted = True \n",
    "# if you want to close the plots immediately \n",
    "# careful: notebook could get very long - if you want to see single subs, go to the cell below\n",
    "close_plots_immediately = True  \n",
    "# if you want to save the plots\n",
    "saving_wanted = True \n",
    "\n",
    "# data in local folder \n",
    "subjectdata = glob.glob(DATA_PATH + '/*.txt')\n",
    "\n",
    "# initialising dataframe \n",
    "autocorr_data = pd.DataFrame()\n",
    "\n",
    "# loading the subject data going through the local folder\n",
    "for sub in subjectdata:\n",
    "    # get the subject ID from data name \n",
    "    subID = sub.partition('VP')[2][0:4]\n",
    "    # read the file and get rid of the brackets\n",
    "    data = pd.read_csv(sub, names=['X','Y']) \n",
    "    data['X'] =  data['X'].apply(lambda x: x.replace('(','').replace(')','')) \n",
    "    data['X'] = data['X'].astype('float')\n",
    "    data['Y'] =  data['Y'].apply(lambda x: x.replace('(','').replace(')','')) \n",
    "    data['Y'] = data['Y'].astype('float')\n",
    "    data_OG_size = data.shape[0]\n",
    "    \n",
    "    # only take coordinates in the interval [0,1[ (thereby also removing 0 entries)\n",
    "    data = data[(data.X>0) & (data.X<=1)]\n",
    "    data = data[(data.Y>0) & (data.Y<=1)]\n",
    "    data_processed_size = data.shape[0]\n",
    "    \n",
    "    removedr = data_OG_size - data_processed_size\n",
    "    proportion = removedr/data_OG_size*100\n",
    "    \n",
    "    print('{}: Removed rows outside interval: {} - Proportion: {}%'.format(sub, removedr, np.int(proportion)))\n",
    "    \n",
    "    # normalising the vector coordinates to unit length (debug: only to check if the autocorrelation changes)\n",
    "    data_norm = pd.DataFrame(normalize([data.X,data.Y]).T, columns=['X','Y'])\n",
    "    \n",
    "    # check if the normalised data is equal to the OG data\n",
    "    if (np.all(np.corrcoef(data.X, data_norm.X))) & (np.all(np.corrcoef(data.Y, data_norm.Y))):\n",
    "    \n",
    "        # adding a time column to the dataframe\n",
    "        data['time'] = data.index*0.03/60.0\n",
    "\n",
    "        # calculating the autocorrelation for each coordinate list with one lag per frame\n",
    "        autoc_X = acf(data['X'],nlags=len(data['X'])-1)\n",
    "        autoc_Y = acf(data['Y'],nlags=len(data['Y'])-1)\n",
    "\n",
    "        # Calculating the median of absolute values on the first 10 second intervall\n",
    "        med_abs_X_10 = np.median(np.absolute(autoc_X[1:300]))\n",
    "        # Calculating the maximum absolute correlation value on the rest of the lag shift list\n",
    "        max_abs_end = np.max(np.absolute(autoc_X[301::]))\n",
    "        # The standard deviation in the first 10 sec interval\n",
    "        std_x_10 = np.std(autoc_X[1:300])\n",
    "        # The standard deviation from 10 sec til end\n",
    "        std_end = np.std(autoc_X[301::])\n",
    "        # filling the dataframe with each subject data point\n",
    "        autocorr_data = autocorr_data.append(\\\n",
    "                                             {'AbsFirstInt': med_abs_X_10, \\\n",
    "                                              'AbsTilEnd': max_abs_end,\\\n",
    "                                              'StdFirstInt': std_x_10, \\\n",
    "                                              'StdTilEnd': std_end},\\\n",
    "                                              ignore_index=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "    # -------------- PLOTTING --------------\n",
    "        if plotting_wanted:\n",
    "        # first of all, plotting the coordinates on screen in a scatter plot\n",
    "            plt.figure(figsize=(10,10))\n",
    "\n",
    "            plt.title(\"Eyes on Screen Coordinates with middle point\")\n",
    "            plt.scatter(data['X'],data['Y'],s=0.1)\n",
    "            plt.scatter(0.5,0.5,s=200)\n",
    "            plt.xlim([0,1])\n",
    "            plt.ylim([0,1])\n",
    "            \n",
    "            if saving_wanted: plt.savefig(PROCESSED_DATA_PATH +'/EyeBox_Scatter_VP' + subID + '.png', quality=90)\n",
    "                \n",
    "            if close_plots_immediately: plt.close()\n",
    "                    \n",
    "            # only continue if size X and Y are equal\n",
    "            if(autoc_X.size == autoc_Y.size):\n",
    "                plt.figure(figsize=(20,20))\n",
    "                # Subplot X corr x unlimited\n",
    "                plt.subplot(4,1,1)\n",
    "                plt.plot(data['time'],autoc_X,ls='-',c='b',linewidth=2)\n",
    "                plt.xlabel('Time (min)',fontsize=20)\n",
    "                plt.ylabel('Correlation (x)',fontsize=20)\n",
    "                plt.xlim([0,np.max(data['time'])])\n",
    "                # add a line at 10 second mark\n",
    "                plt.axvline(x=0.1666666,c='k',linewidth=1)\n",
    "                # Subplot X corr x limited\n",
    "                plt.subplot(4,1,2)\n",
    "                plt.plot(data['time'],autoc_X,ls='-',c='b',linewidth=3)\n",
    "                plt.xlabel('Time (min)',fontsize=20)\n",
    "                plt.ylabel('Correlation (x)',fontsize=20)\n",
    "                plt.xlim([0,1])\n",
    "                # add a line at 10 second mark\n",
    "                plt.axvline(x=0.1666666,c='k',linewidth=1)\n",
    "                # Subplot Y corr x unlimited\n",
    "                plt.subplot(4,1,3)\n",
    "                plt.plot(data['time'],autoc_Y,ls='-',c='g',linewidth=2)\n",
    "                plt.xlabel('Time (min)',fontsize=20)\n",
    "                plt.ylabel('Correlation (y)',fontsize=20)\n",
    "                plt.xlim([0,np.max(data['time'])])\n",
    "                # add a line at 10 second mark\n",
    "                plt.axvline(x=0.1666666,c='k',linewidth=1)\n",
    "                # Subplot Y corr x limited\n",
    "                plt.subplot(4,1,4)\n",
    "                plt.plot(data['time'],autoc_Y,ls='-',c='g',linewidth=3)\n",
    "                plt.xlabel('Time (min)',fontsize=20)\n",
    "                plt.ylabel('Correlation (y)',fontsize=20)\n",
    "                plt.xlim([0,1])\n",
    "                # add a line at 10 second mark\n",
    "                plt.axvline(x=0.1666666,c='k',linewidth=1)\n",
    "\n",
    "    # -------------- SAVING --------------\n",
    "                if saving_wanted: plt.savefig(PROCESSED_DATA_PATH +'/Autocorr_Plot_VP' + subID + '.png', quality=90)\n",
    "                \n",
    "                if close_plots_immediately: plt.close()\n",
    "                    \n",
    "            else:\n",
    "                print('The sizes of autocorrelation array do not match')\n",
    "            \n",
    "    else:\n",
    "        print('Something went wrong - normalising changed the vectors - check them out!')           \n",
    "\n",
    "    \n",
    "autocorr_data    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_PATH + 'EyesOnScreen_VP6387.txt', names=['X','Y']) \n",
    "data['X'] =  data['X'].apply(lambda x: x.replace('(','').replace(')','')) \n",
    "data['X'] = data['X'].astype('float')\n",
    "data['Y'] =  data['Y'].apply(lambda x: x.replace('(','').replace(')','')) \n",
    "data['Y'] = data['Y'].astype('float')\n",
    "\n",
    "#data = data[data.values.sum(axis=1) != 0] \n",
    "\n",
    "#data = data[data.values.sum(axis=1) > 0]\n",
    "#data = data[data.values.sum(axis=1) <= 1]\n",
    "\n",
    "#data = data[(data.values.sum(axis=1) > 0) & (data.values.sum(axis=1) <= 1)]\n",
    "\n",
    "# only take coordinates in the interval [0,1[\n",
    "data = data[(data.X>0) & (data.X<=1)]\n",
    "data = data[(data.Y>0) & (data.Y<=1)]\n",
    "\n",
    "#data = pd.DataFrame(normalize([data.X,data.Y]).T, columns=['X','Y'])\n",
    "\n",
    "data['time'] = data.index*0.03/60.0\n",
    "\n",
    "autoc_X = acf(data['X'],nlags=len(data['X'])-1)\n",
    "autoc_Y = acf(data['Y'],nlags=len(data['Y'])-1)\n",
    "\n",
    "\n",
    "med_abs_X_10 = np.median(np.absolute(autoc_X[1:300]))\n",
    "max_abs_end = np.max(np.absolute(autoc_X[301::]))\n",
    "\n",
    "autocorr_data = pd.DataFrame()\n",
    "autocorr_data = autocorr_data.append({'Median Abs First Intervall': med_abs_X_10, 'Abs til end': max_abs_end}, ignore_index=True)\n",
    "\n",
    "labels = ['X','Y']\n",
    "# Plotting \n",
    "if(autoc_X.size == autoc_Y.size):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    \n",
    "    # Subplot X corr x unlimited\n",
    "    plt.subplot(4,1,1)\n",
    "    plt.plot(data['time'],autoc_X,ls='-',c='b',linewidth=2)\n",
    "    plt.xlabel('Time (min)',fontsize=20)\n",
    "    plt.ylabel('Correlation (x)',fontsize=20)\n",
    "    plt.xlim([0,np.max(data['time'])])\n",
    "    # add a line at 10 second mark\n",
    "    plt.axvline(x=0.1666666,c='k',linewidth=1)\n",
    "    \n",
    "    # Subplot X corr x limited\n",
    "    plt.subplot(4,1,2)\n",
    "    plt.plot(data['time'],autoc_X,ls='-',c='b',linewidth=3)\n",
    "    plt.xlabel('Time (min)',fontsize=20)\n",
    "    plt.ylabel('Correlation (x)',fontsize=20)\n",
    "    plt.xlim([0,1])\n",
    "    # add a line at 10 second mark\n",
    "    plt.axvline(x=0.1666666,c='k',linewidth=1)\n",
    "    \n",
    "    # Subplot Y corr x unlimited\n",
    "    plt.subplot(4,1,3)\n",
    "    plt.plot(data['time'],autoc_Y,ls='-',c='g',linewidth=2)\n",
    "    plt.xlabel('Time (min)',fontsize=20)\n",
    "    plt.ylabel('Correlation (y)',fontsize=20)\n",
    "    plt.xlim([0,np.max(data['time'])])\n",
    "    # add a line at 10 second mark\n",
    "    plt.axvline(x=0.1666666,c='k',linewidth=1)\n",
    "    \n",
    "    # Subplot Y corr x limited\n",
    "    plt.subplot(4,1,4)\n",
    "    plt.plot(data['time'],autoc_Y,ls='-',c='g',linewidth=3)\n",
    "    plt.xlabel('Time (min)',fontsize=20)\n",
    "    plt.ylabel('Correlation (y)',fontsize=20)\n",
    "    plt.xlim([0,1])\n",
    "    # add a line at 10 second mark\n",
    "    plt.axvline(x=0.1666666,c='k',linewidth=1)\n",
    "else:\n",
    "    disp('The sizes of autocorrelation array do not match')\n",
    "\n",
    "    \n",
    "   \n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"Eyes on Screen Coordinates with middle point\")\n",
    "plt.scatter(data['X'],data['Y'],s=0.1)\n",
    "plt.scatter(0.5,0.5,s=200)\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1]) \n",
    "\n",
    "# der erste null durchgang (x koordinate) # Das max des Betrags von allen werten mit höherer verschiebung (irgendein varianzmaß)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxima_X = argrelextrema(np.array(data.X), np.greater)\n",
    "maxima_Y = argrelextrema(np.array(data.Y), np.greater)\n",
    "maxima_Z = argrelextrema(np.array(data.Z), np.greater)\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(maxima_X[0])\n",
    "plt.title(\"X coord\")\n",
    "plt.ylabel(\"Local Maximum Index\")\n",
    "plt.xlabel(\"Local Maximum\")\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(maxima_Y[0])\n",
    "plt.title(\"Y coord\")\n",
    "plt.ylabel(\"Local Maximum Index\")\n",
    "plt.xlabel(\"Local Maximum\")\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(maxima_Z[0])\n",
    "plt.title(\"Z coord\")\n",
    "plt.ylabel(\"Local Maximum Index\")\n",
    "plt.xlabel(\"Local Maximum\")\n",
    "plt.show()\n",
    "\n",
    "X_x = maxima_X[0]\n",
    "X_y = np.arange(0,len(X_x))\n",
    "Y_x = maxima_Y[0]\n",
    "Y_y = np.arange(0,len(Y_x))\n",
    "Z_x = maxima_Z[0]\n",
    "Z_y = np.arange(0,len(Z_x))\n",
    "\n",
    "m_X = (len(X_x) * np.sum(X_x*X_y) - np.sum(X_x) * np.sum(X_y))/(len(X_x)*np.sum(X_x*X_x) - np.sum(X_x) ** 2)\n",
    "m_Y = (len(Y_x) * np.sum(Y_x*Y_y) - np.sum(Y_x) * np.sum(Y_y))/(len(X_x)*np.sum(Y_x*Y_x) - np.sum(Y_x) ** 2)\n",
    "m_Z = (len(Z_x) * np.sum(Z_x*Z_y) - np.sum(Z_x) * np.sum(Z_y))/(len(X_x)*np.sum(Z_x*Z_x) - np.sum(Z_x) ** 2)\n",
    "    \n",
    "#print(\"The best fit slope of X is: \", m_X)\n",
    "print(\"The mean maxima jump (in seconds) is: \", m_X/0.03)\n",
    "#print(\"The best fit slope of Y is: \", m_Y)\n",
    "print(\"The mean maxima jump (in seconds) is: \", m_Y/0.03)\n",
    "#print(\"The best fit slope of Z is: \", m_Z)\n",
    "print(\"The mean maxima jump (in seconds) is: \", m_Z/0.03)\n",
    "print(\"Overall mean jump (in seconds):\", ((m_X/0.03)+(m_Y/0.03)+(m_Z/0.03))/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soa = np.zeros((data.shape[0],6))\n",
    "\n",
    "for i in range(0,data.shape[0],1800):\n",
    "    soa[i,3] = data.X[i]\n",
    "    soa[i,4] = data.X[i]\n",
    "    soa[i,5] = data.X[i]\n",
    "\n",
    "X, Y, Z, U, V, W = zip(*soa)\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.quiver(X, Y, Z, U, V, W)\n",
    "ax.set_xlim([-.008, .008])\n",
    "ax.set_ylim([-.008, .008])\n",
    "ax.set_zlim([-.008, .008])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
